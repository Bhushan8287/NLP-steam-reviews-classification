## ğŸ® Steam Reviews Sentiment Analysis

A binary sentiment classification project using a real-world dataset of Steam game reviews. The goal is to classify user reviews as **positive** or **negative**, using classical NLP techniques and machine learning models.

---

### ğŸ“– Overview
This project demonstrates a machine learning flow for binary text classification using NLP. It covers:
- Data cleaning and preprocessing
- Feature extraction using **BoW**, **TF-IDF**, and **Word2Vec**
- Model training and evaluation (Logistic Regression, etc.)
- Hyperparameter tuning
- Threshold optimization for classification
- Streamlit-based deployment for live inference

The dataset contains 25,000 Steam reviews (trimmed from ~50k for performance reasons). All metrics, models, and preprocessing artifacts are stored in a structured folder hierarchy.

---

### â“ Problem Statement
The task is to predict whether a Steam user review expresses **positive** or **negative** sentiment based on its text content.

---

### ğŸ§° Tech Stack
- Python 
- scikit-learn
- pandas, NumPy
- nltk, gensim
- matplotlib, seaborn
- Streamlit (deployment)
- joblib / pickle

---

### ğŸ“‚ Project Structure
```
.
â”œâ”€â”€ app.py                            # Streamlit app for inference
â”œâ”€â”€ working.ipynb                    # Main development notebook
â”œâ”€â”€ prediction.ipynb                # Inference + threshold tuning
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ steam_reviews_raw.csv
â”‚   â””â”€â”€ steam_reviews_cleaned_25k.csv
â”œâ”€â”€ hyper_tune_models/              # Pickled models after tuning
â”‚   â””â”€â”€ logreg_tfidf.pkl
â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ model_metrics.json
â”œâ”€â”€ pre_processors/
â”‚   â””â”€â”€ tfidf_vectorizer.pkl
â”œâ”€â”€ split_arrays/
â”‚   â”œâ”€â”€ X_train.npy
â”‚   â””â”€â”€ X_test.npy
â”œâ”€â”€ final_model_log_reg.pkl         # Best performing model
â”œâ”€â”€ best_tfidf_vectorizer.pkl       # Used in Streamlit app
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

### âš™ï¸ How It Works
1. **Preprocessing**:
   - Cleaned reviews, removed stopwords, lowercased text
2. **Vectorization**:
   - Used three techniques: BoW, TF-IDF, and Word2Vec
   - Evaluated all three using classical ML models
3. **Model Training & Tuning**:
   - Trained and evaluated models: [logistic regression, multi NB, linear svc, knn, random forest, gradboost, decision trees]
   - Tuned hyperparameters for TF-IDF
4. **Evaluation**:
   - ROC-AUC, F1-score, Precision-Recall, Confusion Matrix
   - Threshold optimization for class prediction
5. **Deployment**:
   - Final TF-IDF + Logistic Regression(best final model) pipeline integrated into Streamlit
   - Hosted on Streamlit Community Cloud

---

### ğŸ“Š Results
- Best performing vectorization: **TF-IDF**
- Final model: **Logistic Regression**
- AUC Score: **[0.9173]**
- Threshold optimized for better precision-recall balance
- Tested the model in `prediction.ipynb`

---

### ğŸš€ Run Locally
```
git clone the repo
pip install -r requirements.txt
streamlit run app.py
```

---

### ğŸ”— Live Demo
Access the deployed Streamlit app here:  
ğŸ‘‰ [Streamlit Cloud URL]()

---

### ğŸ“‰ Limitations
- No use of deep learning (LSTM, BERT) to keep it lightweight
- Models are classical, not neural
- Only binary classification (neutral/ambiguous excluded)

---

### ğŸ”® Future Improvements
- Use BERT or DistilBERT for embeddings
- Integrate MLflow or Weights & Biases for experiment tracking
- Add REST API for backend integration
- Implement real-time data ingestion
- Improve UI/UX of the Streamlit app

---

### ğŸ“œ License
[MIT License](LICENSE)
